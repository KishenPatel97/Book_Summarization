{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bleu.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMpMmm3HqLcao3Pb/mjUD4i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KishenPatel97/Book_Summarization/blob/main/bleu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjYxuFUbdGtt",
        "outputId": "bc944449-fc35-4f07-e8e2-d8c0317a97a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.translate import bleu\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "# from summarize import processBook"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aHedAtrvqqP",
        "outputId": "3484e16c-4378-4b9b-b5b5-36ddbd4d5c04"
      },
      "source": [
        "hypothesis = \"the #### transcript is a written version of each day 's cnn student news program use this transcript to help students with reading comprehension and vocabulary use the weekly newsquiz to test your knowledge of storie s you saw on cnn student news\"\n",
        "\n",
        "reference = \"this page includes the show transcript use the transcript to help students with reading comprehension and vocabulary at the bottom of the page, comment for a chance to be mentioned on cnn student news. you must be a teacher or a student age # # or older to request a mention on the cnn student news roll call . the weekly newsquiz tests students' knowledge of even ts in the news\"\n",
        "\n",
        "hy1 = \"This text is just for testing purposes\"\n",
        "\n",
        "ref1 = \"The article is meant for evaluation\"\n",
        "# Requires text in a tokenized format\n",
        "score1 = bleu(word_tokenize(reference), word_tokenize(hypothesis))\n",
        "print(score1)\n",
        "\n",
        "score2 = bleu([word_tokenize(ref1)], word_tokenize(hyp1))\n",
        "print(score2)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5053483543335474\n",
            "0.7311104457090247\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL5NmEvdykVg"
      },
      "source": [
        "def processBook(fname):\n",
        "    \"\"\" Function to process .txt books, esp. from Gutenberg.\n",
        "    PARAMS: fname (str) - filepath to book to be processed into a string\n",
        "    RETURNS: (str) - the string object containing the text\n",
        "    \"\"\"\n",
        "    book = open(fname)      # open book file\n",
        "    book_lines = []         # initialize storage\n",
        "    for line in book.readlines():       # iterate through each line\n",
        "        book_lines.append(line.strip())     # process each line\n",
        "\n",
        "    return \" \".join(book_lines)         # return processed lines"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggObRxn3NPIf"
      },
      "source": [
        "control1 = processBook('cn_alice.txt')\n",
        "\n",
        "control2 = processBook('gs_alice.txt')\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13_X5ru_SoN2",
        "outputId": "629784b0-312b-46f2-f07c-9adb3beeca64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Requires text in a tokenized format\n",
        "score3 = bleu(word_tokenize(control1), word_tokenize(control2))\n",
        "print(score3)\n",
        "\n",
        "score3_rev = bleu(word_tokenize(control2), word_tokenize(control1))\n",
        "print(score3_rev)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.311900088600225\n",
            "0.23930988821651522\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}